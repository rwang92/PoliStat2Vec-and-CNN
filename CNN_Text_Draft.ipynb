{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN Text Draft.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "EyAhV1K1kSfx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 65
            },
            {
              "item_id": 69
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "a5c4ba47-fab7-4a07-8771-d570332b3848",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520313468250,
          "user_tz": 480,
          "elapsed": 39807,
          "user": {
            "displayName": "Ron Wang",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "101413017425979643796"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.1-cp36-cp36m-linux_x86_64.whl \n",
        "!pip3 install torchvision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==0.3.1 from http://download.pytorch.org/whl/cu80/torch-0.3.1-cp36-cp36m-linux_x86_64.whl\n",
            "  Downloading http://download.pytorch.org/whl/cu80/torch-0.3.1-cp36-cp36m-linux_x86_64.whl (496.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 496.4MB 23.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch==0.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==0.3.1)\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-0.3.1\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.2.0-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 1.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "  Downloading Pillow-5.0.0-cp36-cp36m-manylinux1_x86_64.whl (5.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.9MB 225kB/s \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision)\r\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch->torchvision)\r\n",
            "Installing collected packages: pillow, torchvision\r\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.0.0 torchvision-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pvDepJQrxKTB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 21
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "bfd3d34e-5182-4023-f8c4-54c8cd161036",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520313499039,
          "user_tz": 480,
          "elapsed": 17107,
          "user": {
            "displayName": "Ron Wang",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "101413017425979643796"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install cffi\n",
        "!pip3 install torchwordemb\n",
        "!pip3 install torchtext"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cffi\n",
            "  Downloading cffi-1.11.5-cp36-cp36m-manylinux1_x86_64.whl (421kB)\n",
            "\u001b[K    100% |████████████████████████████████| 430kB 2.4MB/s \n",
            "\u001b[?25hCollecting pycparser (from cffi)\n",
            "  Downloading pycparser-2.18.tar.gz (245kB)\n",
            "\u001b[K    100% |████████████████████████████████| 256kB 3.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pycparser\n",
            "  Running setup.py bdist_wheel for pycparser ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/95/14/9a/5e7b9024459d2a6600aaa64e0ba485325aff7a9ac7489db1b6\n",
            "Successfully built pycparser\n",
            "Installing collected packages: pycparser, cffi\n",
            "Successfully installed cffi-1.11.5 pycparser-2.18\n",
            "Collecting torchwordemb\n",
            "  Downloading torchwordemb-0.0.8.tar.gz\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from torchwordemb)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0.0->torchwordemb)\n",
            "Building wheels for collected packages: torchwordemb\n",
            "  Running setup.py bdist_wheel for torchwordemb ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/e2/5e/7c/155e2563587ed9b93540a3b9aaf1ffbd8fd3eaee2481751cc1\n",
            "Successfully built torchwordemb\n",
            "Installing collected packages: torchwordemb\n",
            "Successfully installed torchwordemb-0.0.8\n",
            "Collecting torchtext\n",
            "  Downloading torchtext-0.2.1-py3-none-any.whl (41kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 1.9MB/s \n",
            "\u001b[?25hCollecting tqdm (from torchtext)\n",
            "  Downloading tqdm-4.19.6-py2.py3-none-any.whl (52kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext)\n",
            "Installing collected packages: tqdm, torchtext\n",
            "Successfully installed torchtext-0.2.1 tqdm-4.19.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BZOAvak0vt-U",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UihacM36xk7-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import torchwordemb\n",
        "\n",
        "vocab, vec = torchwordemb.load_word2vec_bin(\"/path/to/word2vec/model.bin\")\n",
        "print(vec.size())\n",
        "print(vec[ w2v.vocab[\"apple\"] ] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qn-iQrjwxc_W",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "embed = nn.Embedding(num_embeddings, embedding_dim)\n",
        "# pretrained_weight is a numpy matrix of shape (num_embeddings, embedding_dim)\n",
        "embed.weight.data.copy_(torch.from_numpy(pretrained_weight))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EcIovclKcc5m",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "import os\n",
        "\n",
        "import random\n",
        "\n",
        "import tarfile\n",
        "\n",
        "import urllib\n",
        "\n",
        "from torchtext import data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class TarDataset(data.Dataset):\n",
        "\n",
        "    \"\"\"Defines a Dataset loaded from a downloadable tar archive.\n",
        "\n",
        "\n",
        "\n",
        "    Attributes:\n",
        "\n",
        "        url: URL where the tar archive can be downloaded.\n",
        "\n",
        "        filename: Filename of the downloaded tar archive.\n",
        "\n",
        "        dirname: Name of the top-level directory within the zip archive that\n",
        "\n",
        "            contains the data files.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "\n",
        "    def download_or_unzip(cls, root):\n",
        "\n",
        "        path = os.path.join(root, cls.dirname)\n",
        "\n",
        "        if not os.path.isdir(path):\n",
        "\n",
        "            tpath = os.path.join(root, cls.filename)\n",
        "\n",
        "            if not os.path.isfile(tpath):\n",
        "\n",
        "                print('downloading')\n",
        "\n",
        "                urllib.request.urlretrieve(cls.url, tpath)\n",
        "\n",
        "            with tarfile.open(tpath, 'r') as tfile:\n",
        "\n",
        "                print('extracting')\n",
        "\n",
        "                tfile.extractall(root)\n",
        "\n",
        "        return os.path.join(path, '')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class MR(TarDataset):\n",
        "\n",
        "\n",
        "\n",
        "    url = 'https://www.cs.cornell.edu/people/pabo/movie-review-data/rt-polaritydata.tar.gz'\n",
        "\n",
        "    filename = 'rt-polaritydata.tar'\n",
        "\n",
        "    dirname = 'rt-polaritydata'\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "\n",
        "    def sort_key(ex):\n",
        "\n",
        "        return len(ex.text)\n",
        "\n",
        "\n",
        "\n",
        "    def __init__(self, text_field, label_field, path=None, examples=None, **kwargs):\n",
        "\n",
        "        \"\"\"Create an MR dataset instance given a path and fields.\n",
        "\n",
        "\n",
        "\n",
        "        Arguments:\n",
        "\n",
        "            text_field: The field that will be used for text data.\n",
        "\n",
        "            label_field: The field that will be used for label data.\n",
        "\n",
        "            path: Path to the data file.\n",
        "\n",
        "            examples: The examples contain all the data.\n",
        "\n",
        "            Remaining keyword arguments: Passed to the constructor of\n",
        "\n",
        "                data.Dataset.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        def clean_str(string):\n",
        "\n",
        "            \"\"\"\n",
        "\n",
        "            Tokenization/string cleaning for all datasets except for SST.\n",
        "\n",
        "            Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
        "\n",
        "            \"\"\"\n",
        "\n",
        "            string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
        "\n",
        "            string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
        "\n",
        "            string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
        "\n",
        "            string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
        "\n",
        "            string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
        "\n",
        "            string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
        "\n",
        "            string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
        "\n",
        "            string = re.sub(r\",\", \" , \", string)\n",
        "\n",
        "            string = re.sub(r\"!\", \" ! \", string)\n",
        "\n",
        "            string = re.sub(r\"\\(\", \" \\( \", string)\n",
        "\n",
        "            string = re.sub(r\"\\)\", \" \\) \", string)\n",
        "\n",
        "            string = re.sub(r\"\\?\", \" \\? \", string)\n",
        "\n",
        "            string = re.sub(r\"\\s{2,}\", \" \", string)\n",
        "\n",
        "            return string.strip()\n",
        "\n",
        "\n",
        "\n",
        "        text_field.preprocessing = data.Pipeline(clean_str)\n",
        "\n",
        "        fields = [('text', text_field), ('label', label_field)]\n",
        "\n",
        "\n",
        "\n",
        "        if examples is None:\n",
        "\n",
        "            path = self.dirname if path is None else path\n",
        "\n",
        "            examples = []\n",
        "\n",
        "            with open(os.path.join(path, 'rt-polarity.neg'), errors='ignore') as f:\n",
        "\n",
        "                examples += [\n",
        "\n",
        "                    data.Example.fromlist([line, 'negative'], fields) for line in f]\n",
        "\n",
        "            with open(os.path.join(path, 'rt-polarity.pos'), errors='ignore') as f:\n",
        "\n",
        "                examples += [\n",
        "\n",
        "                    data.Example.fromlist([line, 'positive'], fields) for line in f]\n",
        "\n",
        "        super(MR, self).__init__(examples, fields, **kwargs)\n",
        "\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "\n",
        "    def splits(cls, text_field, label_field, dev_ratio=.1, shuffle=True, root='.', **kwargs):\n",
        "\n",
        "        \"\"\"Create dataset objects for splits of the MR dataset.\n",
        "\n",
        "\n",
        "\n",
        "        Arguments:\n",
        "\n",
        "            text_field: The field that will be used for the sentence.\n",
        "\n",
        "            label_field: The field that will be used for label data.\n",
        "\n",
        "            dev_ratio: The ratio that will be used to get split validation dataset.\n",
        "\n",
        "            shuffle: Whether to shuffle the data before split.\n",
        "\n",
        "            root: The root directory that the dataset's zip archive will be\n",
        "\n",
        "                expanded into; therefore the directory in whose trees\n",
        "\n",
        "                subdirectory the data files will be stored.\n",
        "\n",
        "            train: The filename of the train data. Default: 'train.txt'.\n",
        "\n",
        "            Remaining keyword arguments: Passed to the splits method of\n",
        "\n",
        "                Dataset.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        path = cls.download_or_unzip(root)\n",
        "\n",
        "        examples = cls(text_field, label_field, path=path, **kwargs).examples\n",
        "\n",
        "        if shuffle: random.shuffle(examples)\n",
        "\n",
        "        dev_index = -1 * int(dev_ratio*len(examples))\n",
        "\n",
        "\n",
        "\n",
        "        return (cls(text_field, label_field, examples=examples[:dev_index]),\n",
        "\n",
        "                cls(text_field, label_field, examples=examples[dev_index:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HrGit_yMHcRr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class CNN_Text(nn.Module):\n",
        "\n",
        "    \n",
        "\n",
        "    def __init__(self, args):\n",
        "\n",
        "        super(CNN_Text, self).__init__()\n",
        "\n",
        "        self.args = args\n",
        "\n",
        "        V = args.embed_num\n",
        "\n",
        "        D = args.embed_dim\n",
        "\n",
        "        C = args.class_num\n",
        "\n",
        "        Ci = 1\n",
        "\n",
        "        Co = args.kernel_num\n",
        "\n",
        "        Ks = args.kernel_sizes\n",
        "        \n",
        "        G_in=Co\n",
        "        \n",
        "        G_out=args.g_out\n",
        "        \n",
        "        G_l=args.gru_l\n",
        "       \n",
        "        self.embed = nn.Embedding(V, D)\n",
        "\n",
        "        # self.convs1 = [nn.Conv2d(Ci, Co, (K, D)) for K in Ks]\n",
        "\n",
        "        self.convs1 = nn.ModuleList([nn.Conv2d(Ci, Co, (K, D)) for K in Ks])\n",
        "\n",
        "        '''\n",
        "\n",
        "        self.conv13 = nn.Conv2d(Ci, Co, (3, D))\n",
        "\n",
        "        self.conv14 = nn.Conv2d(Ci, Co, (4, D))\n",
        "\n",
        "        self.conv15 = nn.Conv2d(Ci, Co, (5, D))\n",
        "\n",
        "        '''\n",
        "\n",
        "        self.dropout = nn.Dropout(args.dropout)\n",
        "\n",
        "        self.fc1 = nn.Linear(len(Ks)*Co*args.kmax, 256)\n",
        "        \n",
        "        #self.fc1 = nn.Linear(len(Ks)*G_out, 256)\n",
        "        \n",
        "        #self.fc1 = nn.Linear(len(Ks)*G_out , C)\n",
        "        \n",
        "        self.fc2 = nn.Linear(256, C)\n",
        "        \n",
        "        #self.rnn=nn.GRU(G_in, G_out, G_l)\n",
        "        \n",
        "        \n",
        "    def kmax_pooling(self, x, dim, k):\n",
        "      \n",
        "        index = x.topk(k, dim = dim)[1].sort(dim = dim)[0]\n",
        "      \n",
        "        return x.gather(dim, index)\n",
        "        \n",
        "       \n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.embed(x)  # (N, W, D)\n",
        "\n",
        "        if self.args.static:\n",
        "\n",
        "            x = Variable(x)\n",
        "\n",
        "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
        "\n",
        "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)\n",
        "        \n",
        "        #x = [torch.transpose(i, 2, 0) for i in x]\n",
        "        \n",
        "        #x = [torch.transpose(i, 2, 1) for i in x]\n",
        "    \n",
        "        #x = [self.rnn(i)[1].squeeze(1) for i in x]\n",
        "\n",
        "\n",
        "\n",
        "        #x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
        "        \n",
        "        x = [self.kmax_pooling(i, 2, args.kmax).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
        "       \n",
        "        x = torch.cat(x, 1)\n",
        "        \n",
        "        x = x.view(x.size(0),-1)\n",
        "\n",
        "\n",
        "\n",
        "        '''\n",
        "\n",
        "        x1 = self.conv_and_pool(x,self.conv13) #(N,Co)\n",
        "\n",
        "        x2 = self.conv_and_pool(x,self.conv14) #(N,Co)\n",
        "\n",
        "        x3 = self.conv_and_pool(x,self.conv15) #(N,Co)\n",
        "\n",
        "        x = torch.cat((x1, x2, x3), 1) # (N,len(Ks)*Co)\n",
        "\n",
        "        '''\n",
        "\n",
        "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
        "\n",
        "        x = self.fc1(x)  # (N, C)\n",
        "        \n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
        "\n",
        "        logit = self.fc2(x)\n",
        "\n",
        "        return logit\n",
        "      \n",
        "      \n",
        "\n",
        "#    def conv_and_pool(self, x, conv):\n",
        "\n",
        " #       x = F.relu(conv(x)).squeeze(3)  # (N, Co, W)\n",
        "\n",
        "  #      x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
        "\n",
        "   #     return x\n",
        "     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ykBjRLYxA2TP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "\n",
        "import torch.autograd as autograd\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train(train_iter, dev_iter, model, args):\n",
        "\n",
        "#    if args.cuda:\n",
        "\n",
        " #       model.cuda()\n",
        "\n",
        "\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
        "\n",
        "\n",
        "\n",
        "    steps = 0\n",
        "\n",
        "    best_acc = 0\n",
        "\n",
        "    last_step = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(1, args.epochs+1):\n",
        "\n",
        "        for batch in train_iter:\n",
        "\n",
        "            feature, target = batch.text, batch.label\n",
        "\n",
        "            feature.data.t_(), target.data.sub_(1)  # batch first, index align\n",
        "\n",
        "            \n",
        "\n",
        "            feature, target = feature.cuda(), target.cuda()\n",
        "\n",
        "\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            logit = model(feature)\n",
        "\n",
        "\n",
        "\n",
        "            #print('logit vector', logit.size())\n",
        "\n",
        "            #print('target vector', target.size())\n",
        "\n",
        "            loss = F.cross_entropy(logit, target)\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "            steps += 1\n",
        "\n",
        "            if steps % args.log_interval == 0:\n",
        "\n",
        "                corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
        "\n",
        "                accuracy = 100.0 * corrects/batch.batch_size\n",
        "\n",
        "                sys.stdout.write(\n",
        "\n",
        "                    '\\rBatch[{}] - loss: {:.6f}  acc: {:.4f}%({}/{})'.format(steps, \n",
        "\n",
        "                                                                             loss.data[0], \n",
        "\n",
        "                                                                             accuracy,\n",
        "\n",
        "                                                                             corrects,\n",
        "\n",
        "                                                                             batch.batch_size))\n",
        "\n",
        "            if steps % args.test_interval == 0:\n",
        "\n",
        "                dev_acc = eval(dev_iter, model, args)\n",
        "\n",
        "                if dev_acc > best_acc:\n",
        "\n",
        "                    best_acc = dev_acc\n",
        "\n",
        "                    last_step = steps\n",
        "\n",
        "                    if args.save_best:\n",
        "\n",
        "                        save(model, args.save_dir, 'best', steps)\n",
        "\n",
        "                else:\n",
        "\n",
        "                    if steps - last_step >= args.early_stop:\n",
        "\n",
        "                        print('early stop by {} steps.'.format(args.early_stop))\n",
        "\n",
        "            elif steps % args.save_interval == 0:\n",
        "\n",
        "                save(model, args.save_dir, 'snapshot', steps)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def eval(data_iter, model, args):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    corrects, avg_loss = 0, 0\n",
        "\n",
        "    for batch in data_iter:\n",
        "\n",
        "        feature, target = batch.text, batch.label\n",
        "\n",
        "        feature.data.t_(), target.data.sub_(1)  # batch first, index align\n",
        "\n",
        "        feature, target = feature.cuda(), target.cuda()\n",
        "\n",
        "\n",
        "\n",
        "        logit = model(feature)\n",
        "\n",
        "        loss = F.cross_entropy(logit, target, size_average=False)\n",
        "\n",
        "\n",
        "\n",
        "        avg_loss += loss.data[0]\n",
        "\n",
        "        corrects += (torch.max(logit, 1)\n",
        "\n",
        "                     [1].view(target.size()).data == target.data).sum()\n",
        "\n",
        "\n",
        "\n",
        "    size = len(data_iter.dataset)\n",
        "\n",
        "    avg_loss /= size\n",
        "\n",
        "    accuracy = 100.0 * corrects/size\n",
        "\n",
        "    print('\\nEvaluation - loss: {:.6f}  acc: {:.4f}%({}/{}) \\n'.format(avg_loss, \n",
        "\n",
        "                                                                       accuracy, \n",
        "\n",
        "                                                                       corrects, \n",
        "\n",
        "                                                                       size))\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def predict(text, model, text_field, label_feild, cuda_flag):\n",
        "\n",
        "    assert isinstance(text, str)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # text = text_field.tokenize(text)\n",
        "\n",
        "    text = text_field.preprocess(text)\n",
        "\n",
        "    text = [[text_field.vocab.stoi[x] for x in text]]\n",
        "\n",
        "    x = text_field.tensor_type(text)\n",
        "\n",
        "    x = autograd.Variable(x, volatile=True)\n",
        "\n",
        "    if cuda_flag:\n",
        "\n",
        "        x = x.cuda()\n",
        "\n",
        "    print(x)\n",
        "\n",
        "    output = model(x)\n",
        "\n",
        "    _, predicted = torch.max(output, 1)\n",
        "\n",
        "    return label_feild.vocab.itos[predicted.data[0][0]+1]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def save(model, save_dir, save_prefix, steps):\n",
        "\n",
        "    if not os.path.isdir(save_dir):\n",
        "\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    save_prefix = os.path.join(save_dir, save_prefix)\n",
        "\n",
        "    save_path = '{}_steps_{}.pt'.format(save_prefix, steps)\n",
        "\n",
        "    torch.save(model.state_dict(), save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yB8MeWBrHqYT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import argparse\n",
        "\n",
        "import datetime\n",
        "\n",
        "import torch\n",
        "\n",
        "import torchtext.data as data\n",
        "\n",
        "import torchtext.datasets as datasets\n",
        "\n",
        "#import model\n",
        "\n",
        "#import train\n",
        "\n",
        "#import mydatasets\n",
        "\n",
        "\n",
        "class args():\n",
        "  lr=0.001\n",
        "  epochs=200\n",
        "  batch_size=64\n",
        "  log_interval=1\n",
        "  test_interval=100\n",
        "  save_interval=500\n",
        "  save_dir='snapshot'\n",
        "  early_stop=1000\n",
        "  save_best=True\n",
        "  shuffle=False\n",
        "  dropout=0.6\n",
        "  max_norm=3.0\n",
        "  embed_dim=256\n",
        "  kernel_num=150\n",
        "  kernel_sizes='1,2,3,4,5'\n",
        "  static=False\n",
        "  device=1\n",
        "  no_cuda=False\n",
        "  snapshot=None\n",
        "  predict=None\n",
        "  test=False\n",
        "  kmax=5\n",
        "  gru_l=1\n",
        "  g_out=100\n",
        "  #embed_num = len(text_field.vocab)\n",
        "  #class_num = len(label_field.vocab) - 1\n",
        "  #cuda = (not args.no_cuda) and torch.cuda.is_available(); del args.no_cuda\n",
        "  #kernel_sizes = [int(k) for k in args.kernel_sizes.split(',')]\n",
        "  #save_dir = os.path.join(args.save_dir, datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "#parser = argparse.ArgumentParser(description='CNN text classificer')\n",
        "\n",
        "# learning\n",
        "\n",
        "#parser.add_argument('-lr', type=float, default=0.001, help='initial learning rate [default: 0.001]')\n",
        "\n",
        "#parser.add_argument('-epochs', type=int, default=256, help='number of epochs for train [default: 256]')\n",
        "\n",
        "#parser.add_argument('-batch-size', type=int, default=64, help='batch size for training [default: 64]')\n",
        "\n",
        "#parser.add_argument('-log-interval',  type=int, default=1,   help='how many steps to wait before logging training status [default: 1]')\n",
        "\n",
        "#parser.add_argument('-test-interval', type=int, default=100, help='how many steps to wait before testing [default: 100]')\n",
        "\n",
        "#parser.add_argument('-save-interval', type=int, default=500, help='how many steps to wait before saving [default:500]')\n",
        "\n",
        "#parser.add_argument('-save-dir', type=str, default='snapshot', help='where to save the snapshot')\n",
        "\n",
        "#parser.add_argument('-early-stop', type=int, default=1000, help='iteration numbers to stop without performance increasing')\n",
        "\n",
        "#parser.add_argument('-save-best', type=bool, default=True, help='whether to save when get best performance')\n",
        "\n",
        "# data \n",
        "\n",
        "#parser.add_argument('-shuffle', action='store_true', default=False, help='shuffle the data every epoch')\n",
        "\n",
        "# model\n",
        "\n",
        "#parser.add_argument('-dropout', type=float, default=0.5, help='the probability for dropout [default: 0.5]')\n",
        "\n",
        "#parser.add_argument('-max-norm', type=float, default=3.0, help='l2 constraint of parameters [default: 3.0]')\n",
        "\n",
        "#parser.add_argument('-embed-dim', type=int, default=128, help='number of embedding dimension [default: 128]')\n",
        "\n",
        "#parser.add_argument('-kernel-num', type=int, default=100, help='number of each kind of kernel')\n",
        "\n",
        "#parser.add_argument('-kernel-sizes', type=str, default='3,4,5', help='comma-separated kernel size to use for convolution')\n",
        "\n",
        "#parser.add_argument('-static', action='store_true', default=False, help='fix the embedding')\n",
        "\n",
        "# device\n",
        "\n",
        "#parser.add_argument('-device', type=int, default=-1, help='device to use for iterate data, -1 mean cpu [default: -1]')\n",
        "\n",
        "#parser.add_argument('-no-cuda', action='store_true', default=False, help='disable the gpu')\n",
        "\n",
        "# option\n",
        "\n",
        "#parser.add_argument('-snapshot', type=str, default=None, help='filename of model snapshot [default: None]')\n",
        "\n",
        "#parser.add_argument('-predict', type=str, default=None, help='predict the sentence given')\n",
        "\n",
        "#parser.add_argument('-test', action='store_true', default=False, help='train or test')\n",
        "\n",
        "#args = parser.parse_args()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# load SST dataset\n",
        "\n",
        "#def sst(text_field, label_field,  **kargs):\n",
        "\n",
        " #   train_data, dev_data, test_data = datasets.SST.splits(text_field, label_field, fine_grained=True)\n",
        "\n",
        "  #  text_field.build_vocab(train_data, dev_data, test_data)\n",
        "\n",
        "   # label_field.build_vocab(train_data, dev_data, test_data)\n",
        "\n",
        "    #train_iter, dev_iter, test_iter = data.BucketIterator.splits(\n",
        "#\n",
        "#                                       (train_data, dev_data, test_data), \n",
        "#\n",
        "#                                       batch_sizes=(args.batch_size, \n",
        "#\n",
        "#                                                     len(dev_data), \n",
        "#\n",
        "#                                                     len(test_data)),\n",
        "\n",
        "#                                        **kargs)\n",
        "\n",
        "#    return train_iter, dev_iter, test_iter \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# load MR dataset\n",
        "\n",
        "def mr(text_field, label_field, **kargs):\n",
        "\n",
        "    train_data, dev_data = MR.splits(text_field, label_field)\n",
        "\n",
        "    text_field.build_vocab(train_data, dev_data)\n",
        "\n",
        "    label_field.build_vocab(train_data, dev_data)\n",
        "\n",
        "    train_iter, dev_iter = data.Iterator.splits(\n",
        "\n",
        "                                (train_data, dev_data), \n",
        "\n",
        "                                batch_sizes=(args.batch_size, len(dev_data)),\n",
        "\n",
        "                                **kargs)\n",
        "\n",
        "    return train_iter, dev_iter\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# load data\n",
        "\n",
        "print(\"\\nLoading data...\")\n",
        "\n",
        "text_field = data.Field(lower=True)\n",
        "\n",
        "label_field = data.Field(sequential=False)\n",
        "\n",
        "train_iter, dev_iter = mr(text_field, label_field, device=-1, repeat=False)\n",
        "\n",
        "# train_iter, dev_iter, test_iter = sst(text_field, label_field, device=-1, repeat=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# update args and print\n",
        "\n",
        "args.embed_num = len(text_field.vocab)\n",
        "\n",
        "args.class_num = len(label_field.vocab) - 1\n",
        "\n",
        "#args.cuda = (not args.no_cuda) and torch.cuda.is_available(); del args.no_cuda\n",
        "\n",
        "args.kernel_sizes = [int(k) for k in args.kernel_sizes.split(',')]\n",
        "\n",
        "args.save_dir = os.path.join(args.save_dir, datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nParameters:\")\n",
        "\n",
        "for attr, value in sorted(args.__dict__.items()):\n",
        "\n",
        "    print(\"\\t{}={}\".format(attr.upper(), value))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# model\n",
        "\n",
        "cnn = CNN_Text(args).cuda()\n",
        "\n",
        "if args.snapshot is not None:\n",
        "\n",
        "    print('\\nLoading model from {}...'.format(args.snapshot))\n",
        "\n",
        "    cnn.load_state_dict(torch.load(args.snapshot))\n",
        "\n",
        "\n",
        "\n",
        "#if args.cuda:\n",
        "\n",
        "#torch.cuda.set_device()\n",
        "\n",
        "#cnn = cnn.cuda()\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "# train or predict\n",
        "\n",
        "if args.predict is not None:\n",
        "\n",
        "    label = train.predict(args.predict, cnn, text_field, label_field, args.cuda)\n",
        "\n",
        "    print('\\n[Text]  {}\\n[Label] {}\\n'.format(args.predict, label))\n",
        "\n",
        "elif args.test:\n",
        "\n",
        "    try:\n",
        "\n",
        "        eval(test_iter, cnn, args) \n",
        "\n",
        "    except Exception as e:\n",
        "\n",
        "        print(\"\\nSorry. The test dataset doesn't  exist.\\n\")\n",
        "\n",
        "else:\n",
        "\n",
        "    print()\n",
        "\n",
        "    try:\n",
        "\n",
        "        train(train_iter, dev_iter, cnn, args)\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "\n",
        "        print('\\n' + '-' * 89)\n",
        "\n",
        "        print('Exiting from training early')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gG-FEpk4Yw__",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Draft"
      ]
    },
    {
      "metadata": {
        "id": "QbiVPDY2J5i_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for batch in train_iter:\n",
        "    print(batch.label)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z-ocAlif0mo3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def kmax_pooling(x, dim, k):\n",
        "    index = x.topk(k, dim = dim)[1].sort(dim = dim)[0]\n",
        "    return x.gather(dim, index)\n",
        "\n",
        "x = torch.rand(1, 7, 4, 5)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qwpcGG5z26Ks",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class ll(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    \n",
        "    super(ll, self).__init__()\n",
        "    \n",
        "    self.cc=nn.ModuleList([nn.Conv2d(1, 100, (K, 4)) for K in [3,4,5]])\n",
        "    \n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    self.fc1 = nn.Linear(len([3,4,5])*100*4, 2)\n",
        "    \n",
        "  def kmax_pooling(x, dim, k):\n",
        "    \n",
        "    index = x.topk(k, dim = dim)[1].sort(dim = dim)[0]\n",
        "    \n",
        "    return x.gather(dim, index)\n",
        "    \n",
        "  def forward(self,x):\n",
        "    \n",
        "    x = [conv(x).squeeze(3) for conv in self.cc]\n",
        "    \n",
        "    x = [kmax_pooling(i, 2, 4).squeeze(2) for i in x]\n",
        "    \n",
        "    x = torch.cat(x,1)\n",
        "    \n",
        "    x=x.view(x.size(0),-1)\n",
        "    \n",
        "    #x = self.dropout(x)  # (N, len(Ks)*Co)\n",
        "\n",
        "    #x = self.fc1(x)  # (N, C)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ib2OKFslIEju",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "class ll(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    \n",
        "    super(ll, self).__init__()\n",
        "    \n",
        "    self.cc=nn.ModuleList([nn.Conv2d(1, 100, (K, 4)) for K in [3,4,5]])\n",
        "    \n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    self.fc1 = nn.Linear(len([3,4,5])*200, 2)\n",
        "    \n",
        "    self.rnn=nn.GRU(100,200,1)\n",
        "    \n",
        "  def kmax_pooling(x, dim, k):\n",
        "    \n",
        "    index = x.topk(k, dim = dim)[1].sort(dim = dim)[0]\n",
        "    \n",
        "    return x.gather(dim, index)\n",
        "    \n",
        "    \n",
        "  def forward(self,x):\n",
        "    \n",
        "    x = [conv(x).squeeze(3) for conv in self.cc]\n",
        "    \n",
        "    x = [torch.transpose(i, 2, 0) for i in x]\n",
        "    \n",
        "    x = [torch.transpose(i, 2, 1) for i in x]\n",
        "    \n",
        "    x = [self.rnn(i)[1].squeeze(1) for i in x]\n",
        "    \n",
        "    \n",
        "    \n",
        "    x = torch.cat(x,1)\n",
        "    \n",
        "    x=x.view(x.size(0),-1)\n",
        "    \n",
        "    x = self.dropout(x)  # (N, len(Ks)*Co)\n",
        "\n",
        "    x = self.fc1(x)  # (N, C)\n",
        "    \n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_M_XvrHx-Efa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "217b9b6f-8866-4d36-90dd-386b954683ae",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520157821054,
          "user_tz": 480,
          "elapsed": 336,
          "user": {
            "displayName": "Ron Wang",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "101413017425979643796"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "x=Variable(torch.rand(1,40,200)).cuda()\n",
        "\n",
        "#p=ll()\n",
        "\n",
        "#u=p(x)\n",
        "\n",
        "p=CNN_Text(args).cuda()\n",
        "\n",
        "p(x)\n",
        "\n",
        "#u\n",
        "\n",
        "\n",
        "#u = [torch.transpose(i, 2, 0) for i in u]\n",
        "\n",
        "#u = [torch.transpose(i, 2, 1) for i in u]\n",
        "\n",
        "#rnn = nn.GRU(100, 100, 1)\n",
        "\n",
        "#u = [rnn(i)[1] for i in u]\n",
        "\n",
        "\n",
        "\n",
        "#u=torch.transpose(u, 2, 0)\n",
        "\n",
        "#u=torch.transpose(u, 2, 1)\n",
        "\n",
        "\n",
        "\n",
        "#rnn = nn.LSTM(100, 100, 1)\n",
        "\n",
        "#output, hn = rnn(u)\n"
      ],
      "execution_count": 322,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Variable containing:\n",
              " 0.0000 -0.1180\n",
              "[torch.cuda.FloatTensor of size 1x2 (GPU 0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 322
        }
      ]
    },
    {
      "metadata": {
        "id": "6assXUP4Y-3r",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "bb1f2d0b-dfea-4a36-eef2-7813f6a900b7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520139764530,
          "user_tz": 480,
          "elapsed": 401,
          "user": {
            "displayName": "Ron Wang",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "101413017425979643796"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "z = Variable(torch.rand(2, 3, 5))\n",
        "z.t()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Variable containing:\n",
              "(0 ,.,.) = \n",
              "  0.9864  0.1194  0.9939  0.9386  0.7324\n",
              "  0.4424  0.9293  0.4787  0.2224  0.9564\n",
              "\n",
              "(1 ,.,.) = \n",
              "  0.3188  0.0591  0.8272  0.2634  0.6105\n",
              "  0.8466  0.3520  0.1231  0.1331  0.2259\n",
              "\n",
              "(2 ,.,.) = \n",
              "  0.2348  0.7077  0.1340  0.1809  0.3188\n",
              "  0.9936  0.5889  0.2112  0.6763  0.0063\n",
              "[torch.FloatTensor of size 3x2x5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "id": "4ndjhPDnyGHe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "29c3c86b-ad73-4e09-d323-32166007fb84",
        "executionInfo": {
          "status": "error",
          "timestamp": 1520137522618,
          "user_tz": 480,
          "elapsed": 368,
          "user": {
            "displayName": "Ron Wang",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "101413017425979643796"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "x=Variable(torch.rand(1,1,40,4))\n",
        "\n",
        "p=ll()\n",
        "\n",
        "s=p(x)[0]\n",
        "\n",
        "def kmax_pooling(x, dim, k):\n",
        "    \n",
        "    index = x.topk(k, dim = dim)[1].sort(dim = dim)[0]\n",
        "    \n",
        "    return x.gather(dim, index)\n",
        "\n",
        "#s.topk(4, dim = 2)[1].sort(dim = 2)[0]\n",
        "\n",
        "#kmax_pooling(s,2,4)\n",
        "\n",
        "[kmax_pooling(i, 2, 4).squeeze(2) for i in p(x)]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-d374d6fd0493>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#kmax_pooling(s,2,4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mkmax_pooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-45-d374d6fd0493>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#kmax_pooling(s,2,4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mkmax_pooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-45-d374d6fd0493>\u001b[0m in \u001b[0;36mkmax_pooling\u001b[0;34m(x, dim, k)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mkmax_pooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: dimension out of range (expected to be in range of [-1, 0], but got 2)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "AQRfqz1NLo7r",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "outputId": "b80194ef-fe56-4e46-8d2d-0d4f782e1426",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520148392401,
          "user_tz": 480,
          "elapsed": 335,
          "user": {
            "displayName": "Ron Wang",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "101413017425979643796"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "rnn = nn.GRU(100, 100, 2)\n",
        "input = torch.randn(100, 1 ,100)\n",
        "rnn(Variable(input))[1].squeeze(1)\n"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Variable containing:\n",
              "\n",
              "Columns 0 to 9 \n",
              "-0.4315 -0.0872  0.3948  0.3150  0.0041  0.0375  0.5397  0.2245  0.4934  0.3367\n",
              " 0.0040 -0.1512 -0.1987 -0.1027 -0.0789 -0.0378  0.0512  0.0830 -0.1289 -0.1766\n",
              "\n",
              "Columns 10 to 19 \n",
              "-0.0272 -0.2784 -0.4954  0.2914 -0.4315  0.3496  0.3775  0.2233  0.1320  0.0389\n",
              " 0.1935 -0.1346  0.0160 -0.1850  0.0617 -0.1704  0.0322  0.0400 -0.4134  0.0483\n",
              "\n",
              "Columns 20 to 29 \n",
              " 0.2431 -0.0432 -0.3716 -0.3888 -0.4464  0.1502  0.0768  0.2435  0.4199 -0.4847\n",
              "-0.2294  0.0129 -0.0168 -0.3497  0.0461 -0.2200  0.0180 -0.0607 -0.0598 -0.2125\n",
              "\n",
              "Columns 30 to 39 \n",
              " 0.0708  0.0165  0.5297 -0.0770  0.4444  0.1545 -0.3218 -0.0366 -0.0221  0.3145\n",
              "-0.2074  0.1367 -0.2058  0.0369  0.1248  0.0607  0.2150  0.0263  0.0605 -0.3468\n",
              "\n",
              "Columns 40 to 49 \n",
              "-0.2220  0.0920 -0.6153 -0.0299  0.1329 -0.1236  0.1708 -0.5577  0.0240  0.0146\n",
              " 0.1071 -0.0852  0.1101  0.0991 -0.0776  0.0403  0.0118  0.2446  0.2504  0.1969\n",
              "\n",
              "Columns 50 to 59 \n",
              "-0.4161 -0.4925  0.1867  0.5797 -0.3331  0.0798  0.0577  0.2673 -0.1540  0.2551\n",
              "-0.1061 -0.0269 -0.0626  0.0380 -0.1266 -0.0132  0.1505 -0.1605  0.2284 -0.0489\n",
              "\n",
              "Columns 60 to 69 \n",
              "-0.1874 -0.1911 -0.4699 -0.0064 -0.3225  0.0794 -0.0876  0.4159 -0.4540  0.2365\n",
              "-0.1167  0.3475  0.0531  0.1299  0.0365 -0.0858  0.1627 -0.0499  0.1612  0.1869\n",
              "\n",
              "Columns 70 to 79 \n",
              "-0.2553 -0.0497  0.0528  0.0249 -0.3791 -0.5468 -0.2141  0.2316 -0.3368  0.1692\n",
              " 0.1878 -0.0087 -0.0746  0.0305  0.3103  0.0334  0.2366  0.2723  0.2206  0.0485\n",
              "\n",
              "Columns 80 to 89 \n",
              "-0.1070 -0.2736 -0.5578 -0.3305  0.2210  0.3896  0.2722  0.7053 -0.2219  0.1594\n",
              " 0.1520 -0.2011 -0.0449 -0.2850 -0.1769  0.1495  0.2188  0.1480  0.2701 -0.1709\n",
              "\n",
              "Columns 90 to 99 \n",
              "-0.1935  0.3016 -0.4434  0.3225 -0.4215  0.3467  0.0967  0.0117 -0.3266 -0.2334\n",
              " 0.0294  0.1137  0.0950 -0.1439  0.1941 -0.1340  0.1208 -0.1008 -0.0330 -0.1014\n",
              "[torch.FloatTensor of size 2x100]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    }
  ]
}